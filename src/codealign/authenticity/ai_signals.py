from typing import Dict, Any, List
import json
import logging
from codealign import client

logger = logging.getLogger(__name__)

def detect_ai_signals(code: str) -> Dict[str, Any]:
    """
    Detects potential AI-generated code patterns using LLM analysis.
    Checks for:
    - Text-book style comments
    - Generic variable naming
    - Over-explanation
    - Specific AI phrasing
    """
    system_prompt = """You are an expert in detecting AI-generated code. 
    Analyze the provided code for signs that it was generated by an LLM (like ChatGPT, Gemini, etc.).
    Look for:
    1. Overly verbose or textbook-style comments (e.g., "Field to store value").
    2. Generic variable names (foo, bar, temp_list) where context suggests better ones.
    3. Traces of AI conversation (e.g., "Here is the code", "Sure").
    4. Perfect, unnatural formatting.
    
    Output JSON:
    {
        "is_suspicious": boolean,
        "confidence": float (0.0 to 1.0),
        "signals": ["signal 1", "signal 2", ...]
    }
    """
    
    user_prompt = f"Analyze this code:\n\n{code[:4000]}" # Truncate if too long
    
    try:
        response_text = client.generate_text(system_prompt, user_prompt, json_mode=True, temperature=0.1)
        if response_text:
            return json.loads(response_text)
    except Exception as e:
        logger.error(f"AI detection failed: {e}")
        
    # Fallback to simple heuristics if LLM fails
    signals = []
    confidence = 0.0
    ai_phrases = ["here is the python code", "certainly", "sure, here is", "# driver code"]
    code_lower = code.lower()
    for phrase in ai_phrases:
        if phrase in code_lower:
            signals.append(f"Contains AI-phrase: '{phrase}'")
            confidence += 0.3
            
    return {
        "is_suspicious": confidence > 0.3,
        "confidence": min(confidence, 0.8), # Cap heuristic confidence
        "signals": signals
    }
